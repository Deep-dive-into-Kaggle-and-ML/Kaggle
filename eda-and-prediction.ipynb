{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Load packages and data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.feature_selection import SelectFromModel\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-31T12:05:18.683925Z","iopub.execute_input":"2021-10-31T12:05:18.684435Z","iopub.status.idle":"2021-10-31T12:05:21.132450Z","shell.execute_reply.started":"2021-10-31T12:05:18.684333Z","shell.execute_reply":"2021-10-31T12:05:21.131471Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/porto-seguro-safe-driver-prediction/train.csv')\ntest = pd.read_csv('../input/porto-seguro-safe-driver-prediction/test.csv')\n\nprint(train.shape)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:05:21.134421Z","iopub.execute_input":"2021-10-31T12:05:21.134686Z","iopub.status.idle":"2021-10-31T12:05:31.568099Z","shell.execute_reply.started":"2021-10-31T12:05:21.134653Z","shell.execute_reply":"2021-10-31T12:05:31.567150Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"markdown","source":" + Missing value가 많은 변수는 제거한다.","metadata":{}},{"cell_type":"code","source":"# check missing percentage\ntrain = train.replace(-1, np.nan)\nna_count = train.isna().sum().sort_values(ascending = False).reset_index()\nna_count.rename(columns = {'index':'variable', 0: 'count'}, inplace = True)\nna_count['prop'] = na_count['count']/train.shape[0]\nna_count[na_count['count']>0]","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:05:31.569540Z","iopub.execute_input":"2021-10-31T12:05:31.569859Z","iopub.status.idle":"2021-10-31T12:05:31.778781Z","shell.execute_reply.started":"2021-10-31T12:05:31.569817Z","shell.execute_reply":"2021-10-31T12:05:31.777918Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"cols_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]\ntrain.drop(cols_to_drop, axis = 1, inplace = True)\ntest.drop(cols_to_drop, axis = 1, inplace = True)\n\n# missing value가 많은 변수 제거\nvars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']\ntrain.drop(vars_to_drop, inplace=True, axis=1)\ntest.drop(vars_to_drop, inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:05:31.780553Z","iopub.execute_input":"2021-10-31T12:05:31.780843Z","iopub.status.idle":"2021-10-31T12:05:32.183770Z","shell.execute_reply.started":"2021-10-31T12:05:31.780813Z","shell.execute_reply":"2021-10-31T12:05:32.182907Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# 이전 커널과 똑같은 target encoding 기법\ndef add_noise(series, noise_level):\n    return series * (1 + noise_level * np.random.randn(len(series)))\n\ndef target_encode(trn_series=None, \n                  tst_series=None, \n                  target=None, \n                  min_samples_leaf=1, \n                  smoothing=1,\n                  noise_level=0):\n    \"\"\"\n    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n    trn_series : training categorical feature as a pd.Series\n    tst_series : test categorical feature as a pd.Series\n    target : target data as a pd.Series\n    min_samples_leaf (int) : minimum samples to take category average into account\n    smoothing (int) : smoothing effect to balance categorical average vs prior  \n    \"\"\" \n    assert len(trn_series) == len(target)\n    assert trn_series.name == tst_series.name\n    temp = pd.concat([trn_series, target], axis=1)\n    # Compute target mean \n    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n    # Compute smoothing\n    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n    # Apply average function to all target data\n    prior = target.mean()\n    # The bigger the count the less full_avg is taken into account\n    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n    # Apply averages to trn and tst series\n    ft_trn_series = pd.merge(\n        trn_series.to_frame(trn_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=trn_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_trn_series.index = trn_series.index \n    ft_tst_series = pd.merge(\n        tst_series.to_frame(tst_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=tst_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_tst_series.index = tst_series.index\n    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:05:32.184950Z","iopub.execute_input":"2021-10-31T12:05:32.185206Z","iopub.status.idle":"2021-10-31T12:05:32.199210Z","shell.execute_reply.started":"2021-10-31T12:05:32.185177Z","shell.execute_reply":"2021-10-31T12:05:32.198266Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":" + 카테고리가 지나치게 많은 변수(high cardinality)를 Target encoding 한다.","metadata":{}},{"cell_type":"code","source":"# high cardinality 특성을 가진 변수 Target Encoding\nprint('The number of categories: ', train['ps_car_11_cat'].nunique())\n\ntrain_encoded, test_encoded = target_encode(train[\"ps_car_11_cat\"], \n                             test[\"ps_car_11_cat\"], \n                             target=train.target, \n                             min_samples_leaf=100,\n                             smoothing=10,\n                             noise_level=0.01)\n    \ntrain['ps_car_11_cat_te'] = train_encoded\ntrain.drop('ps_car_11_cat', axis=1, inplace=True)\ntest['ps_car_11_cat_te'] = test_encoded\ntest.drop('ps_car_11_cat', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:05:32.200791Z","iopub.execute_input":"2021-10-31T12:05:32.201109Z","iopub.status.idle":"2021-10-31T12:05:32.638218Z","shell.execute_reply.started":"2021-10-31T12:05:32.201052Z","shell.execute_reply":"2021-10-31T12:05:32.637366Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Undersampling\n + Target의 클래스 1과 0의 비율 차이가 매우 크므로(imbalanced), undersampling을 진행한다.\n  + Undersampling을 할 경우, overfitting을 방지할 순 있지만 데이터의 손실이 발생해 정확도가 떨어질 수 있다는 문제점이 있다.","metadata":{}},{"cell_type":"code","source":"desired_apriori=0.10\n\nidx_0 = train[train['target'] == 0].index\nidx_1 = train[train['target'] == 1].index\n\nnb_0 = len(train.loc[idx_0])\nnb_1 = len(train.loc[idx_1])\n\nundersampling_rate = ((1-desired_apriori)*nb_1)/(nb_0*desired_apriori)\nundersampled_nb_0 = int(undersampling_rate*nb_0)\nprint('Rate to undersample records with target=0: {}'.format(undersampling_rate))\nprint('Number of records with target=0 after undersampling: {}'.format(undersampled_nb_0))\n\nunder_idx = shuffle(idx_0, n_samples = undersampled_nb_0, random_state = 0)\nidx_list  = list(under_idx) + list(idx_1)\n\ntrain = train.loc[idx_list].reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:05:32.639387Z","iopub.execute_input":"2021-10-31T12:05:32.639614Z","iopub.status.idle":"2021-10-31T12:05:32.972577Z","shell.execute_reply.started":"2021-10-31T12:05:32.639584Z","shell.execute_reply":"2021-10-31T12:05:32.971931Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"targets = pd.DataFrame(train['target'].value_counts().reset_index())\ntargets['prop'] = targets['target']/train.shape[0]\n\nplt.figure(figsize = (6, 4))\nax = plt.subplot(1, 1, 1)\nsns.barplot(targets['index'], targets['target'], palette = ['#006699', '#cc0000'], alpha = 0.6, edgecolor = 'k')\nfor s in [\"top\",\"right\",\"left\"]:\n    ax.spines[s].set_visible(False)\nax.grid(axis='y', linestyle='-', alpha=0.4)\n\nplt.title('Target Distribution after Undersampling', fontweight = 'bold', fontsize = 15, pad = 20)\nplt.xlabel('Target', fontweight = 'bold'); plt.ylabel('Count', fontweight = 'bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:05:32.973590Z","iopub.execute_input":"2021-10-31T12:05:32.973958Z","iopub.status.idle":"2021-10-31T12:05:33.221091Z","shell.execute_reply.started":"2021-10-31T12:05:32.973923Z","shell.execute_reply":"2021-10-31T12:05:33.220504Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# replace -1 with NaN\ntrain = train.replace(-1, np.nan)\ntest = test.replace(-1, np.nan)\n\n# One-hot encoding: categorical variables\ncat_features = [a for a in train.columns if a.endswith('cat')]\n\nfor column in cat_features:\n    temp = pd.get_dummies(pd.Series(train[column]))\n    train = pd.concat([train,temp],axis=1)\n    train = train.drop([column],axis=1)\n    \nfor column in cat_features:\n    temp = pd.get_dummies(pd.Series(test[column]))\n    test = pd.concat([test,temp],axis=1)\n    test = test.drop([column],axis=1)\n    \nid_test = test['id'].values\ntarget_train = train['target'].values\n\ntrain = train.drop(['target','id'], axis = 1)\ntest = test.drop(['id'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:05:33.222240Z","iopub.execute_input":"2021-10-31T12:05:33.222594Z","iopub.status.idle":"2021-10-31T12:05:37.777486Z","shell.execute_reply.started":"2021-10-31T12:05:33.222565Z","shell.execute_reply":"2021-10-31T12:05:37.776523Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# check final data\nprint('Train set: {}'.format(train.shape))\nprint('Test set: {}'.format(test.shape))","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:05:37.779731Z","iopub.execute_input":"2021-10-31T12:05:37.779964Z","iopub.status.idle":"2021-10-31T12:05:37.784537Z","shell.execute_reply.started":"2021-10-31T12:05:37.779935Z","shell.execute_reply":"2021-10-31T12:05:37.783665Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Stacking Ensemble\n1. 각 모델별로 원본 train/test set을 예측한 결과값을 기반으로 메타 모델을 위한 meta train/test set을 생성한다.(자세한 내용은 스터디 때 공유)\n2. 1에서 개별 모델들이 생성한 train set을 모두 stacking 형태로 합쳐서 메타 모델이 학습할 최종 메타 데이터셋을 생성한다. \n\n + 기본적인 Stacking을 사용할 경우, overfitting 문제가 발생할 수 있기 때문에 CV 기반 Stacking을 주로 많이 사용한다.","metadata":{}},{"cell_type":"markdown","source":"#### 간단한 Gini 계수 계산법 - Gini 계수와 ROC/AUC의 연관\n<https://luckytoilet.wordpress.com/2018/04/04/useful-properties-of-roc-curves-auc-scoring-and-gini-coefficients/>","metadata":{}},{"cell_type":"code","source":"class Ensemble(object):\n    def __init__(self, n_splits, stacker, base_models):\n        self.n_splits = n_splits\n        self.stacker = stacker\n        self.base_models = base_models\n        \n    def fit_predict(self, X, y, T):\n        X = np.array(X) # X_train\n        y = np.array(y) # y_train\n        T = np.array(T) # test set\n        \n        \n        folds = list(StratifiedKFold(n_splits = self.n_splits, shuffle = True, random_state = 0).split(X, y))\n        \n        # meta train, test for stacking model\n        S_train = np.zeros((X.shape[0], len(self.base_models)))\n        S_test = np.zeros((T.shape[0], len(self.base_models)))\n        \n        for i, model in enumerate(self.base_models):\n            # 각 폴드별 meta test set 생성\n            S_test_i = np.zeros((T.shape[0], self.n_splits))\n            for j, (train_idx, test_idx) in enumerate(folds):\n                X_train = X[train_idx]\n                y_train = y[train_idx]\n                X_holdout = X[test_idx]\n                \n                print(\"Base model %d: fit %s model | fold %d\" %(i+1, str(model.__class__.__name__), j+1))\n                \n                model.fit(X_train, y_train)\n                cross_score = cross_val_score(model, X_train, y_train, cv = 3, scoring = 'roc_auc')\n                print(\"cross_score [roc-auc]: %.5f [gini]: %.5f\" % (cross_score.mean(), 2*cross_score.mean()-1))\n                \n                y_pred = model.predict_proba(X_holdout)[:,1]\n                S_train[test_idx, i] = y_pred # meta train set\n                S_test_i[:, j] = model.predict_proba(T)[:,1]\n            S_test[:, i] = S_test_i.mean(axis = 1) # meta test set: 각 fold에서 구한 probability의 평균 \n            \n        results = cross_val_score(self.stacker, S_train, y, cv = 3, scoring = 'roc_auc')\n        print(\"Stacker score [gini]: %.5f\" % (2 * results.mean() - 1))\n        \n        self.stacker.fit(S_train, y)\n        res = self.stacker.predict_proba(S_test)[:, 1]\n        return res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LightGBM params\n# lgb_1\nlgb_params1 = {}\nlgb_params1['learning_rate'] = 0.02\nlgb_params1['n_estimators'] = 650\nlgb_params1['max_bin'] = 10\nlgb_params1['subsample'] = 0.8\nlgb_params1['subsample_freq'] = 10\nlgb_params1['colsample_bytree'] = 0.8   \nlgb_params1['min_child_samples'] = 500\nlgb_params1['seed'] = 314\nlgb_params1['num_threads'] = 4\n\n# lgb2\nlgb_params2 = {}\nlgb_params2['n_estimators'] = 1090\nlgb_params2['learning_rate'] = 0.02\nlgb_params2['colsample_bytree'] = 0.3   \nlgb_params2['subsample'] = 0.7\nlgb_params2['subsample_freq'] = 2\nlgb_params2['num_leaves'] = 16\nlgb_params2['seed'] = 314\nlgb_params2['num_threads'] = 4\n\n# lgb3\nlgb_params3 = {}\nlgb_params3['n_estimators'] = 1100\nlgb_params3['max_depth'] = 4\nlgb_params3['learning_rate'] = 0.02\nlgb_params3['seed'] = 314\nlgb_params3['num_threads'] = 4\n\n# XGBoost params\nxgb_params = {}\nxgb_params['objective'] = 'binary:logistic'\nxgb_params['learning_rate'] = 0.04\nxgb_params['n_estimators'] = 490\nxgb_params['max_depth'] = 4\nxgb_params['subsample'] = 0.9\nxgb_params['colsample_bytree'] = 0.9  \nxgb_params['min_child_weight'] = 10\nxgb_params['num_threads'] = 4","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:38:07.409150Z","iopub.execute_input":"2021-10-31T12:38:07.409441Z","iopub.status.idle":"2021-10-31T12:38:07.420277Z","shell.execute_reply.started":"2021-10-31T12:38:07.409408Z","shell.execute_reply":"2021-10-31T12:38:07.419315Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Base models\nlgb_model1 = LGBMClassifier(**lgb_params1)\nlgb_model2 = LGBMClassifier(**lgb_params2)\nlgb_model3 = LGBMClassifier(**lgb_params3)\nxgb_model = XGBClassifier(**xgb_params)\n\n# Stacking model - response가 binary이므로 LR 모델 생성\nlog_model = LogisticRegression()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:16:43.410768Z","iopub.execute_input":"2021-10-31T12:16:43.411546Z","iopub.status.idle":"2021-10-31T12:16:43.416938Z","shell.execute_reply.started":"2021-10-31T12:16:43.411498Z","shell.execute_reply":"2021-10-31T12:16:43.416097Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"stack = Ensemble(n_splits = 3,\n        stacker = log_model,\n        base_models = (lgb_model1, lgb_model2, lgb_model3, xgb_model))  ","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:16:45.564493Z","iopub.execute_input":"2021-10-31T12:16:45.564912Z","iopub.status.idle":"2021-10-31T12:16:45.569760Z","shell.execute_reply.started":"2021-10-31T12:16:45.564881Z","shell.execute_reply":"2021-10-31T12:16:45.568973Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"y_prediction = stack.fit_predict(train, target_train, test) ","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:16:47.286596Z","iopub.execute_input":"2021-10-31T12:16:47.287055Z","iopub.status.idle":"2021-10-31T12:26:22.026629Z","shell.execute_reply.started":"2021-10-31T12:16:47.287007Z","shell.execute_reply":"2021-10-31T12:26:22.025508Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[]}]}