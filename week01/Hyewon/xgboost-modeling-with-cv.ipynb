{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# XGBoolst Modeling 커널 필사\n + Link: [XGBoost CV](https://www.kaggle.com/aharless/xgboost-cv-lb-284/notebook)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom numba import jit\nimport time\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-28T07:32:39.341897Z","iopub.execute_input":"2021-10-28T07:32:39.342222Z","iopub.status.idle":"2021-10-28T07:32:39.349042Z","shell.execute_reply.started":"2021-10-28T07:32:39.342187Z","shell.execute_reply":"2021-10-28T07:32:39.347746Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation metric: Gini index","metadata":{}},{"cell_type":"code","source":"@jit\ndef eval_gini(y_true, y_prob):\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    ntrue = 0\n    gini = 0\n    delta = 0\n    n = len(y_true)\n    for i in range(n-1, -1, -1):\n        y_i = y_true[i]\n        ntrue += y_i\n        gini += y_i*delta\n        delta += 1-y_i\n    gini = 1-2*gini/(ntrue*(n-ntrue))\n    return gini","metadata":{"execution":{"iopub.status.busy":"2021-10-28T07:08:08.344561Z","iopub.execute_input":"2021-10-28T07:08:08.345025Z","iopub.status.idle":"2021-10-28T07:08:08.566997Z","shell.execute_reply.started":"2021-10-28T07:08:08.344976Z","shell.execute_reply":"2021-10-28T07:08:08.566317Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Target Encoding\nTarget encode categorical variables with **high cardinality**\n\n + [Target Encoding 원리에 대한 참고자료](https://towardsdatascience.com/all-about-target-encoding-d356c4e9e82)\n + 아래 코드는 Target Encoding 과정을 모두 풀어서 코딩했지만, 대안으로 `TargetEncoder` 함수 사용하면 더 쉽고 빠르게 Target Encoding 가능하다.","metadata":{}},{"cell_type":"code","source":"def gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = -eval_gini(labels, preds)\n    return [('gini', gini_score)]\n\ndef add_noise(series, noise_level): # noise 역할 - 해당 코드에서는 noise_level을 0으로 설정 --> noise 역할 x\n    return series*(1+noise_level*np.random.randn(len(series)))\n\n# 각 categorical variable에 대해 수행 --> Target encoding 원리\ndef target_encode(trn_series = None,    \n                  val_series = None,\n                  tst_series = None,\n                  target = None,\n                  min_samples_leaf = 1,\n                  smoothing = 1,\n                  noise_level = 0):\n\n    assert len(trn_series) == len(target)\n    assert trn_series.name == tst_series.name\n    temp = pd.concat([trn_series, target], axis = 1)\n    \n    # 각 카테고리에 대해 target = 1일 확률 계산\n    averages = temp.groupby(trn_series.name)[target.name].agg(['mean', 'count']) \n    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n    \n    # 전체 데이터에서 target = 1일 확률 계산\n    prior = target.mean()\n    averages[target.name] = prior * (1-smoothing) + averages['mean'] * smoothing\n    averages.drop(['mean', 'count'], axis = 1, inplace = True)\n    \n    ft_trn_series = pd.merge(trn_series.to_frame(trn_series.name),\n                             averages.reset_index().rename(columns = {'index': target.name, target.name: 'average'}),\n                             on = trn_series.name,\n                             how = 'left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    ft_trn_series.index = trn_series.index\n    \n    ft_val_series = pd.merge(\n        val_series.to_frame(val_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=val_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    ft_val_series.index = val_series.index\n    \n    ft_tst_series = pd.merge(\n        tst_series.to_frame(tst_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=tst_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    ft_tst_series.index = tst_series.index\n    \n    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T07:07:56.372417Z","iopub.execute_input":"2021-10-28T07:07:56.372713Z","iopub.status.idle":"2021-10-28T07:07:56.391756Z","shell.execute_reply.started":"2021-10-28T07:07:56.372684Z","shell.execute_reply":"2021-10-28T07:07:56.390803Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load data and select features","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/porto-seguro-safe-driver-prediction/train.csv', na_values=\"-1\") # .iloc[0:200,:]\ntest_df = pd.read_csv('../input/porto-seguro-safe-driver-prediction/test.csv', na_values=\"-1\")","metadata":{"execution":{"iopub.status.busy":"2021-10-28T07:08:11.221740Z","iopub.execute_input":"2021-10-28T07:08:11.222040Z","iopub.status.idle":"2021-10-28T07:08:24.122009Z","shell.execute_reply.started":"2021-10-28T07:08:11.222006Z","shell.execute_reply":"2021-10-28T07:08:24.118991Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_features = [\n    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n]\n# add combinations - strongly correlated features\ncombs = [\n    ('ps_reg_01', 'ps_car_02_cat'),  \n    ('ps_reg_01', 'ps_car_04_cat'),\n]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T07:08:24.126896Z","iopub.execute_input":"2021-10-28T07:08:24.127824Z","iopub.status.idle":"2021-10-28T07:08:24.151762Z","shell.execute_reply.started":"2021-10-28T07:08:24.127723Z","shell.execute_reply":"2021-10-28T07:08:24.148573Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Combine stronly related features and Label Encoding\n 1. 설명변수 중 correlation이 강한 변수들의 combination을 생성한다.\n 2. combination을 생성한 후 Label Encoding을 한다.","metadata":{}},{"cell_type":"code","source":"id_test = test_df['id'].values\nid_train = train_df['id'].values\ny = train_df['target']\n\nstart = time.time()\nfor n_c, (f1, f2) in enumerate(combs):\n    name1 = f1 + '_plus_' + f2\n    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + '_' + train_df[f2].apply(lambda x: str(x))\n    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + '_' + test_df[f2].apply(lambda x: str(x))\n    \n    lbl = LabelEncoder()\n    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values)) # train, test의 모든 카테고리 고려하여 Label Encoding\n    train_df[name1] = lbl.transform(list(train_df[name1].values))\n    test_df[name1] = lbl.transform(list(test_df[name1].values))\n    \n    train_features.append(name1)\n    \nX = train_df[train_features]\ntest_df = test_df[train_features]\n\nf_cats = [f for f in X.columns if '_cat' in f]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T07:14:48.315873Z","iopub.execute_input":"2021-10-28T07:14:48.316163Z","iopub.status.idle":"2021-10-28T07:14:57.151321Z","shell.execute_reply.started":"2021-10-28T07:14:48.316135Z","shell.execute_reply":"2021-10-28T07:14:57.150174Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"y_valid_pred = 0*y\ny_test_pred = 0","metadata":{"execution":{"iopub.status.busy":"2021-10-28T07:15:07.759566Z","iopub.execute_input":"2021-10-28T07:15:07.759858Z","iopub.status.idle":"2021-10-28T07:15:07.765577Z","shell.execute_reply.started":"2021-10-28T07:15:07.759826Z","shell.execute_reply":"2021-10-28T07:15:07.764683Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation + Modeling\n + 참고 커널에서는 KFold CV 방법을 사용했으나, EDA에서 target class의 비율이 매우 불균형했기 때문에 한 fold에 클래스 0에 해당하는 데이터만 들어가는 것을 방지하기 위해 **Stratified KFold**로 바꿔주었다. 그 결과, gini index 값이 감소하였다.","metadata":{}},{"cell_type":"code","source":"K = 5\nkf = StratifiedKFold(n_splits = K, random_state = 1, shuffle = True)\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T07:15:09.568787Z","iopub.execute_input":"2021-10-28T07:15:09.569186Z","iopub.status.idle":"2021-10-28T07:15:09.575836Z","shell.execute_reply.started":"2021-10-28T07:15:09.569139Z","shell.execute_reply":"2021-10-28T07:15:09.574659Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"MAX_ROUNDS = 500\nOPTIMIZE_ROUNDS = False\nLEARNING_RATE = 0.07\nEARLY_STOPPING_ROUNDS = 50  \n\n# XGBoost 모델 정의\nmodel = XGBClassifier(    \n                        n_estimators = MAX_ROUNDS,\n                        max_depth = 4,\n                        objective = \"binary:logistic\",\n                        learning_rate = LEARNING_RATE, \n                        subsample = .8,\n                        min_child_weight = 6,\n                        colsample_bytree = .8,\n                        scale_pos_weight = 1.6,\n                        gamma = 10,\n                        reg_alpha = 8,\n                        reg_lambda = 1.3,\n                     )","metadata":{"execution":{"iopub.status.busy":"2021-10-28T07:15:55.225790Z","iopub.execute_input":"2021-10-28T07:15:55.226092Z","iopub.status.idle":"2021-10-28T07:15:55.233077Z","shell.execute_reply.started":"2021-10-28T07:15:55.226062Z","shell.execute_reply":"2021-10-28T07:15:55.232211Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Process\n 1. CV로 데이터를 총 5개의 폴드로 나눈다.\n 2. 각 CV마다 target encoding 후 모델을 학습한다. 이 때 early stopping을 적용할지 말지로 모델 학습 방법이 다르다.\n 3. Validation set을 예측한 후, 클래스에 대한 예측 확률값을 구한다.\n 4. 5개의 fold에서 각각 Test set을 예측한 후, 예측 확률의 평균을 구한다.","metadata":{}},{"cell_type":"code","source":"for i, (train_idx, test_idx) in enumerate(kf.split(train_df, y)):\n    X_train, X_valid = X.iloc[train_idx, :].copy(), X.iloc[test_idx, :].copy()\n    y_train, y_valid = y[train_idx].copy(), y[test_idx].copy()\n    X_test = test_df.copy()\n    \n    print('\\nFold ', i)\n    \n    for f in f_cats:\n        X_train[f + '_avg'], X_valid[f + '_avg'], X_test[f + '_avg'] = target_encode(trn_series = X_train[f],\n                                                                                     val_series = X_valid[f],\n                                                                                     tst_series = X_test[f],\n                                                                                     target = y_train,\n                                                                                     min_samples_leaf = 200,\n                                                                                     smoothing = 10,\n                                                                                     noise_level = 0\n                                                                                     )\n    if OPTIMIZE_ROUNDS:\n        eval_set = [(X_valid, y_valid)]\n        fit_model = model.fit(X_train, y_train, eval_set = eval_set,\n                             eval_metric = gini_xgb, early_stopping_rounds = EARLY_STOPPING_ROUNDS,\n                             verbose = False)\n        print( \"  Best N trees = \", model.best_ntree_limit )\n        print( \"  Best gini = \", model.best_score )\n        \n    else:\n        fit_model = model.fit(X_train, y_train)\n    \n    pred = fit_model.predict_proba(X_valid)[:, 1] # class 1에 대한 예측 확률값\n    print(' Gini = ', eval_gini(y_valid, pred))\n    y_valid_pred.iloc[test_idx] = pred\n    \n    y_test_pred += fit_model.predict_proba(X_test)[:, 1]\n    \n    del X_test, X_train, X_valid, y_train\n    \ny_test_pred /= K # average prediction probablility \n\nprint('\\nGini for full training set:')\neval_gini(y, y_valid_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T07:32:44.329564Z","iopub.execute_input":"2021-10-28T07:32:44.329836Z","iopub.status.idle":"2021-10-28T07:50:20.345080Z","shell.execute_reply.started":"2021-10-28T07:32:44.329808Z","shell.execute_reply":"2021-10-28T07:50:20.344034Z"},"trusted":true},"execution_count":17,"outputs":[]}]}